{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR_A3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "00q9G20SsKnr"
      },
      "source": [
        "from google.colab import drive\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gybMidfWbMam",
        "outputId": "634a411e-d9d9-4e0a-ed24-ffd87d57ef3a"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxuCbJ5NvtlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0bb73f-ff1d-4d18-870b-979ebecc84dd"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "% cd /content/drive/MyDrive/cran/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/cran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsGZySprbO22"
      },
      "source": [
        "import re\n",
        "def remove_symbols(line):\n",
        "  return re.sub('[^A-Za-z0-9\\s]+', '', line).lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6eVJFUcvw5O"
      },
      "source": [
        "# Create Posting List for title and body zones\n",
        "# posting is for body\n",
        "# posting_t is for title\n",
        "\n",
        "posting = {}\n",
        "posting_t = {}\n",
        "\n",
        "with open('IR3_OUTPUTS/OP0.txt') as f:\n",
        "  next(f)\n",
        "  for line in f:\n",
        "    word, *docs = line.strip().split(' ')\n",
        "\n",
        "    posting[word] = set(docs)\n",
        "\n",
        "with open('IR3_OUTPUTS/titles.txt') as f:\n",
        "  next(f)\n",
        "  for line in f:\n",
        "    word, *docs = line.strip().split(' ')\n",
        "\n",
        "    posting_t[word] = set(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv1OXQpTypaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3302cf6-b5f3-41b4-ad06-2d6b0703cd7d"
      },
      "source": [
        "def find_docs(word1, *words):\n",
        "  res = posting[word1]\n",
        "\n",
        "  for word in words:\n",
        "    if word[0:2] == '~ ':\n",
        "      res = res.difference(posting[word[2:]])\n",
        "    elif word[0:2] == '* ':\n",
        "      res = res.intersection(posting[word[2:]])\n",
        "    elif word[0:2] == '| ':\n",
        "      res = res.union(posting[word[2:]])\n",
        "    else:\n",
        "      print(\"Invalid operator\")\n",
        "      break\n",
        "\n",
        "  return list(res)\n",
        "  # return doc_id_to_title(list(res))\n",
        "\n",
        "\n",
        "print(find_docs('doppler', '| divers', '| perturb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['26', '1110', '1370', '496', '73', '1248', '447', '1154', '1224', '499', '305', '299', '70', '131', '149', '613', '916', '903', '21', '1203', '660', '324', '371', '129']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgM1OjIkFwhv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_doc_from_query(terms):\n",
        "  # Use this function to compute the matrix\n",
        "  \n",
        "  weighted = np.zeros((1400, 2)) # 1400 -> no of docs\n",
        "  # weights = np.array([0.3, 0.7])\n",
        "  # weights = np.reshape(weights, (-1, 1))\n",
        "\n",
        "  title_docs = find_docs_from_zone(terms, zone='title')\n",
        "  body_docs = find_docs_from_zone(terms)\n",
        "\n",
        "  for t in title_docs:\n",
        "    if t == '':\n",
        "      continue\n",
        "    weighted[int(t)-1][0] = 1.\n",
        "  for b in body_docs:\n",
        "    weighted[int(b)-1][1] = 1.\n",
        "  \n",
        "  # print(weighted[328])\n",
        "  # for i in weighted:\n",
        "  #   if i[0] == 1 and i[1] == 1:\n",
        "  #     print(i)\n",
        "  # print(title_docs)\n",
        "  # print(body_docs)\n",
        "\n",
        "  # res = np.dot(weighted, weights)\n",
        "  return weighted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hg7CXSVXvtZ"
      },
      "source": [
        "def find_docs_from_zone(terms, zone='body'):\n",
        "  # word1 = terms[0]\n",
        "  if zone == 'body':\n",
        "    res = posting[terms[0]]\n",
        "  elif zone == 'title':\n",
        "    res = posting_t[terms[0]]\n",
        "\n",
        "  for word in terms[1:]:\n",
        "    if zone == 'body':\n",
        "      res = res.union(posting.get(word, ''))\n",
        "    elif zone == 'title':\n",
        "      res = res.union(posting_t.get(word, ''))\n",
        "\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLDyFL62C3N4"
      },
      "source": [
        "query = 'what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .'\n",
        "\n",
        "res = ''\n",
        "for x in remove_symbols(query).strip().split():\n",
        "  if x not in stop_words:\n",
        "    res += ' ' + porter.stem(x)\n",
        "\n",
        "weighted = find_doc_from_query(res.strip().split())\n",
        "# print(find_doc_from_query(res.strip().split()))\n",
        "# res.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyMLdT0FyCdo"
      },
      "source": [
        "# This code snippet is only for first query\n",
        "\n",
        "\n",
        "rel = np.zeros((1400, 1))\n",
        "with open(f'cranqrel') as f:\n",
        "  for line in f:\n",
        "    row = line.strip().split()\n",
        "    # print(row[0])\n",
        "    if not row[0] == str(1):\n",
        "      continue\n",
        "    rel[int(row[1])-1][0] = 1.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.linalg.pinv(weighted)  # this is showing error, (1400, 2) matrix is not invertible ig, so I took the pseudo inverse of weighted\n",
        "result = np.dot(a, rel)\n",
        "result  # but the result is showing [0 0]T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uav05LxW9vM1",
        "outputId": "9876695f-30b6-496a-c6ab-d63d605024f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05374606],\n",
              "       [0.0125    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz2rrg3ATqrZ"
      },
      "source": [
        "BLOCK_SIZE = 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToyGhAYwn6zI"
      },
      "source": [
        "# Block-Sort Based Indexing Algorithm Implementation\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def cran_bsbi():\n",
        "  freq_dict = defaultdict(set)\n",
        "  id_to_title = defaultdict(set)\n",
        "  doc_id = 0\n",
        "  total_files = 0\n",
        "  current_block = 0\n",
        "  A = 0\n",
        "  B = 0\n",
        "  T = 0\n",
        "  i = 0\n",
        "\n",
        "  with open('cran.all.1400') as f:\n",
        "    for line in f:\n",
        "\n",
        "      # if i < 5:\n",
        "      #   print(line)\n",
        "      # else:\n",
        "      #   break\n",
        "      i = i + 1\n",
        "\n",
        "      if line[0:2] == '.I':\n",
        "        doc_id = int(line[3:].strip())\n",
        "        A = 0\n",
        "        B = 0\n",
        "        continue\n",
        "\n",
        "      if line[0:2] == '.T':\n",
        "        # id_to_title[word] = ''\n",
        "        T = 1\n",
        "        continue\n",
        "      \n",
        "      if line[0:2] == '.A':\n",
        "        A = 1\n",
        "        T = 0\n",
        "        continue\n",
        "      \n",
        "      if line[0:2] == '.B':\n",
        "        B = 1\n",
        "        A = 0\n",
        "        continue\n",
        "\n",
        "      if line[0:2] == '.W':\n",
        "        B = 0\n",
        "\n",
        "      if A == 1 or B == 1:\n",
        "        continue\n",
        "      \n",
        "\n",
        "      for word in line.split():\n",
        "        word = remove_symbols(word)\n",
        "        if word and word not in stop_words:\n",
        "          word = porter.stem(word)\n",
        "          \n",
        "          if word not in freq_dict:\n",
        "            current_block += 1\n",
        "\n",
        "          if not freq_dict[word].__contains__(doc_id):\n",
        "            freq_dict[word].add(doc_id)\n",
        "            current_block += 1\n",
        "\n",
        "          if T == 1 and not id_to_title[word].__contains__(doc_id):\n",
        "            id_to_title[word].add(doc_id)\n",
        "        \n",
        "        if current_block >= BLOCK_SIZE:\n",
        "          sorted_list = sorted(freq_dict.items(), key= lambda _: _[0])\n",
        "\n",
        "          with open(f'./IR3_OUTPUTS/OP{total_files}.txt', 'w') as f:\n",
        "            for word, doc_ids in sorted_list:\n",
        "              f.write(word)\n",
        "              for id in doc_ids:\n",
        "                f.write(f' {id}')\n",
        "              f.write('\\n')\n",
        "\n",
        "          current_block = 0\n",
        "          freq_dict.clear()\n",
        "          total_files += 1\n",
        "          print (i + ' rows done!')\n",
        "\n",
        "    sorted_list = sorted(freq_dict.items(), key= lambda _: _[0])\n",
        "    sorted_title_list = sorted(id_to_title.items(), key= lambda _: _[0])\n",
        "\n",
        "    if len(sorted_list) > 0:\n",
        "      with open(f'./IR3_OUTPUTS/OP{total_files}.txt', 'w') as f:\n",
        "        for word, doc_ids in sorted_list:\n",
        "          f.write(word)\n",
        "          for id in doc_ids:\n",
        "            f.write(f' {id}')\n",
        "          f.write('\\n')\n",
        "      \n",
        "    if len(sorted_title_list) > 0:\n",
        "      with open(f'./IR3_OUTPUTS/titles.txt', 'w') as f:\n",
        "        for word, doc_ids in sorted_title_list:\n",
        "          f.write(word)\n",
        "          for id in doc_ids:\n",
        "            f.write(f' {id}')\n",
        "          f.write('\\n')\n",
        "\n",
        "      current_block = 0\n",
        "      freq_dict.clear()\n",
        "      total_files += 1\n",
        "\n",
        "cran_bsbi()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jQvtugp57n6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854da4ae-cda4-4ebc-c292-85ace09710d6"
      },
      "source": [
        "# Weighted Zone Scoring\n",
        "query = 'what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .'\n",
        "\n",
        "res = ''\n",
        "for x in remove_symbols(query).strip().split():\n",
        "  if x not in stop_words:\n",
        "    res += ' ' + porter.stem(x)\n",
        "\n",
        "scores = find_doc_from_query(res.strip().split())\n",
        "# print(find_doc_from_query(res.strip().split()))\n",
        "# res.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'119', '260', '631', '1191', '550', '1168', '1303', '797', '792', '81', '70', '508', '944', '55', '283', '586', '1395', '725', '615', '671', '518', '54', '655', '1050', '399', '1159', '1264', '179', '1274', '638', '303', '1164', '790', '215', '269', '209', '1341', '1062', '82', '1161', '555', '519', '1163', '754', '711', '799', '877', '662', '962', '500', '1165', '916', '982', '181', '485', '1226', '139', '349', '37', '413', '359', '387', '315', '7', '959', '292', '141', '1166', '685', '1114', '924', '51', '253', '248', '302', '251', '442', '174', '252', '1281', '23', '147', '651', '593', '391', '1104', '270', '53', '687', '1201', '435', '430', '1212', '566', '983', '1107', '879', '563', '486', '666', '679', '755', '242', '1213', '395', '872', '559', '1197', '546', '572', '1386', '431', '1207', '358', '493', '513', '1089', '665', '707', '1192', '1393', '1084', '914', '1064', '1219', '211', '781', '817', '1268', '22', '1098', '945', '814', '80', '244', '670', '536', '700', '1320', '102', '1389', '539', '874', '433', '1144', '927', '883', '327', '239', '52', '715', '436', '540', '240', '158', '584', '1012', '568', '810', '878', '264', '378', '776', '184', '976', '876', '859', '1002', '66', '285', '579', '406', '429', '800', '904', '909', '767', '709', '193', '689', '45', '564', '1140', '1091', '1169', '120', '78', '1106', '464', '1147', '925', '668', '1366', '238', '875', '1258', '225', '747', '860', '1090', '441', '796', '565', '60', '923', '311', '686', '154', '29', '101', '1128', '795', '57', '509', '1167', '1339', '56', '542', '1096', '396', '1263', '6', '585', '280', '226', '1162', '98', '1340', '5', '1285', '1289', '873', '1300', '606', '1380', '571', '197', '1328', '643', '784', '630', '522', '1394', '1111', '524', '144', '1348', '861', '1319', '100', '1177', '383', '168', '1305', '222', '1185', '676', '316', '1361', '1149', '865', '398', '438', '963', '973', '1063', '1155', '352', '104', '746', '437', '41', '704', '497', '11', '560', '176', '991', '350', '40', '789', '1314', '911', '295', '683', '62', '339', '12', '373', '495', '880', '1204', '1362', '309', '325', '774', '708', '47', '421', '663', '635', '24', '1124', '554', '204', '159', '334', '13', '516', '21', '294', '552', '202', '142', '300', '623', '95'}\n",
            "{'921', '119', '217', '420', '27', '121', '1121', '83', '550', '447', '1344', '811', '1303', '792', '70', '1356', '944', '283', '586', '452', '725', '1391', '268', '671', '54', '284', '576', '562', '399', '1264', '179', '1252', '462', '757', '625', '1274', '726', '1355', '353', '206', '333', '1164', '20', '999', '589', '1073', '269', '1229', '980', '209', '1236', '1341', '156', '858', '118', '555', '975', '519', '526', '754', '267', '1230', '877', '1378', '573', '465', '500', '791', '525', '982', '624', '485', '1226', '1324', '139', '220', '724', '42', '37', '359', '1346', '1181', '1011', '218', '538', '35', '141', '44', '177', '140', '1166', '884', '685', '85', '490', '51', '641', '673', '1218', '251', '815', '808', '491', '442', '174', '296', '252', '986', '701', '185', '928', '23', '147', '506', '672', '198', '84', '2', '274', '702', '1201', '1212', '297', '566', '476', '145', '397', '520', '1001', '870', '1250', '466', '235', '388', '486', '604', '77', '755', '679', '1213', '1100', '1059', '395', '36', '288', '172', '1386', '990', '74', '262', '1207', '1261', '493', '1254', '1199', '665', '1089', '338', '125', '236', '1393', '1084', '124', '481', '390', '1379', '211', '781', '569', '817', '951', '199', '1268', '974', '871', '1098', '360', '945', '449', '511', '1051', '97', '946', '626', '229', '19', '536', '700', '1179', '719', '826', '1320', '657', '1354', '102', '89', '539', '180', '874', '327', '52', '1183', '715', '773', '1381', '128', '240', '567', '158', '1157', '584', '445', '1160', '649', '720', '378', '776', '1195', '443', '574', '66', '285', '529', '1184', '429', '1310', '1196', '904', '75', '909', '767', '205', '472', '709', '193', '1299', '1345', '591', '588', '751', '1279', '1351', '1248', '439', '582', '1091', '937', '78', '1106', '1147', '73', '668', '1366', '1153', '925', '875', '344', '1258', '860', '1003', '1322', '441', '565', '1277', '923', '1396', '154', '101', '636', '795', '489', '1167', '1074', '49', '1339', '621', '56', '1375', '542', '978', '1096', '1263', '690', '6', '280', '226', '1162', '98', '759', '1340', '5', '446', '1285', '605', '1380', '606', '1222', '834', '571', '882', '1265', '197', '801', '630', '366', '643', '524', '61', '28', '1348', '69', '1177', '383', '364', '1282', '676', '581', '583', '316', '335', '1149', '345', '1349', '398', '208', '227', '223', '973', '1063', '1350', '1155', '352', '104', '822', '746', '437', '1158', '1343', '729', '704', '497', '1178', '11', '110', '67', '195', '176', '40', '941', '601', '1385', '789', '886', '1297', '911', '33', '295', '1334', '1034', '1180', '146', '1309', '681', '90', '603', '232', '703', '308', '1296', '164', '1304', '495', '1362', '325', '47', '708', '421', '635', '24', '575', '1315', '1239', '1124', '401', '76', '204', '202', '516', '21', '1255', '552', '1198', '553', '142', '918', '300', '95', '578', '964', '329', '260', '1099', '631', '245', '1191', '1203', '1298', '1168', '1251', '739', '797', '81', '508', '1125', '343', '55', '658', '1395', '255', '894', '615', '997', '1071', '407', '518', '1095', '655', '1050', '68', '1159', '618', '638', '740', '303', '348', '790', '1335', '714', '215', '473', '88', '1062', '82', '1161', '169', '1307', '1321', '1163', '656', '711', '96', '799', '662', '962', '1373', '453', '1165', '189', '798', '805', '1056', '916', '417', '1280', '181', '314', '1336', '1028', '628', '1008', '349', '413', '1206', '960', '201', '404', '123', '713', '387', '758', '315', '7', '1271', '370', '1260', '959', '1015', '1270', '292', '1337', '1365', '1332', '1312', '122', '1072', '1338', '824', '328', '304', '463', '1114', '131', '722', '924', '253', '1325', '248', '302', '165', '620', '1235', '170', '869', '783', '72', '1372', '1281', '331', '108', '838', '651', '593', '629', '1290', '541', '1097', '391', '1104', '270', '764', '53', '192', '1186', '687', '435', '430', '1170', '717', '1286', '983', '549', '1107', '879', '721', '563', '908', '306', '666', '1043', '242', '107', '968', '1295', '872', '559', '1197', '546', '572', '305', '640', '135', '431', '804', '243', '272', '358', '818', '513', '707', '577', '660', '1192', '166', '1202', '634', '1088', '947', '914', '1064', '1219', '342', '1232', '456', '494', '1101', '646', '1225', '994', '214', '216', '979', '22', '814', '80', '244', '670', '157', '14', '1294', '173', '213', '371', '1389', '695', '433', '1144', '927', '25', '883', '1205', '862', '239', '103', '436', '948', '677', '540', '92', '1012', '568', '810', '1065', '878', '1007', '264', '184', '976', '876', '263', '859', '1002', '728', '579', '972', '1246', '406', '836', '733', '1081', '800', '414', '756', '689', '645', '45', '1194', '354', '564', '1134', '416', '58', '79', '1140', '1216', '1169', '667', '661', '712', '120', '903', '32', '9', '464', '917', '499', '675', '238', '1224', '1399', '225', '747', '1090', '966', '374', '1154', '796', '60', '1313', '1175', '812', '152', '686', '311', '219', '1000', '29', '592', '1128', '57', '1244', '509', '440', '699', '919', '1113', '602', '547', '30', '396', '347', '585', '1311', '1115', '794', '873', '129', '1289', '1300', '762', '423', '1328', '633', '784', '522', '94', '1394', '1111', '160', '50', '34', '1061', '1151', '144', '415', '861', '1319', '100', '410', '380', '168', '888', '1305', '222', '1185', '1361', '163', '865', '682', '438', '963', '1292', '41', '212', '530', '587', '332', '293', '1215', '1066', '560', '991', '1040', '1026', '1327', '350', '698', '310', '543', '1042', '1093', '1374', '1314', '683', '981', '1110', '62', '339', '1242', '1241', '12', '1077', '373', '880', '1204', '309', '261', '774', '1037', '114', '663', '1347', '468', '1217', '91', '554', '1331', '1103', '159', '230', '334', '13', '294', '183', '1200', '623', '455', '1048'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI062w2i0lZT",
        "outputId": "b4ecd1fc-7e4e-410d-bbe0-4c1b0fcbe3bd"
      },
      "source": [
        "diff = np.subtract(rel, scores)\n",
        "sum = np.sum(diff, axis=0)\n",
        "sum\n",
        "# error = sum**2\n",
        "# error[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-624.])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmiBbPjxAegw",
        "outputId": "e89ecfa6-1d42-4b9f-a5c4-3b6e2b6022c9"
      },
      "source": [
        "len(posting)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6391"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVYOgMLoW6d8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}